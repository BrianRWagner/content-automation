name: Daily Content Automation

on:
  schedule:
    - cron: '0 9 * * *'  # Daily at 9 AM UTC
  workflow_dispatch:  # Manual trigger

jobs:
  scrape-content:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 feedparser
    
    - name: Run content scraper
      run: python content_scraper.py
    
    - name: Get current date
      id: date
      run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
    
    - name: Send email report
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 465
        secure: true
        username: ${{ secrets.EMAIL_USERNAME }}
        password: ${{ secrets.EMAIL_PASSWORD }}
        subject: "Daily Content Report - ${{ steps.date.outputs.date }}"
        to: ${{ secrets.EMAIL_TO }}
        from: "Content Automation <${{ secrets.EMAIL_USERNAME }}>"
        body: |
          Your daily content automation has completed successfully!
          
          Found quality content from your 57 premium sources.
          
          ATTACHMENTS:
          • content_queue.csv - LinkedIn posts ready to copy-paste
          • content_report.txt - Full detailed report
          
          Simply open the CSV file and copy posts from the "LinkedIn Post" column.
          
          Automation runs daily at 9 AM UTC.
        attachments: |
          content_queue.csv
          content_report.txt
